---
title: Day-15 Hadoop生态圈各框架的功能分析
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---


# HDFS的优缺点
## HDFS的优点：
        1、处理超大文件
                这里的超大文件通常是指百MB、甚至数百TB大小的文件。目前在实际应用中，HDFS已经能用来存储管理PB级的数据了。
        2、流式的访问数据
                HDFS的设计建立在“一次写入、多次读写”任务的基础上。这意味着一个数据集一旦由数据源生成，就会被复制分发到不同的存储节点中，然后响应各种各样的数据分析任务请求。在多数情况下，分析任务都会涉及数据集中的大部分数据，也就是说，对HDFS来说，请求读取整个数据集要比读取一条记录更加高效。
        3、运行于廉价的商用机器集群上
                Hadoop设计对应急需求比较低，只须运行在低廉的商用硬件集群上，而无需在昂贵的高可用性机器上。廉价的商用机也就意味着大型集群中出现节点故障情况的概率非常高。HDFS遇到了上述故障时，被设计成能够继续运行且不让用户察觉到明显的中断。
## HDFS的缺点：
        1、不适合低延迟数据访问
                如果要处理一些用户要求时间比较短的低延迟应用请求，则HDFS不适合。HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。
                改进策略：
                        对于那些有低延时要求的应用程序，HBase是一个更好的选择，通过上层数据管理项目尽可能地弥补这个不足。在性能上有了很大的提升，它的口号是goes real time。使用缓存或多个master设计可以降低Clinet的数据请求压力，以减少延时。
        2、无法高效存储大量的小文件
                因为NameNode把文件系统的元数据放置在内存中，所有文件系统所能容纳的文件数目是由NameNode的内存大小来决定。还有一个问题就是，因为MapTask的数量是由Splits来决定的，所以用MR处理大量的小文件时，就会产生过多的MapTask，线程管理开销将会增加作业时间。当Hadoop处理很多小文件(文件大小小于HDFS中Block大小)的时候，由于FileInputFormat不会对小文件进行划分，所以每一个小文件都会被当做一个Split并分配一个Map任务，导致效率底下。
                例如：一个1G的文件，会被划分成16个64MB的Split，并分配16个Map任务处理，而10000个100Kb的文件会被10000个Map任务处理。
                改进策略：
                        要想让HDFS能处理好小文件，有不少方法。利用SequenceFile、MapFile、Har等方式归档小文件，这个方法的原理就是把小文件归档起来管理，HBase就是基于此的。
        3、不支持多用户写入及任意修改文件
                在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作，目前HDFS还不支持多个用户对同一文件的写操作，以及在文件任意位置进行修改。

## 综合
HDFS优点：
>1.    高容错性。
a)      数据自动保存多个副本
b)      副本丢失后，自动恢复
2.    适合批处理
a)      移动计算而非移动数据
b)      数据位置暴露给计算框架
3.    适合大数据处理
a)      GB、TB、甚至PB级数据
b)      百万规模以上的文件数量
c)       10K + 节点
4.    可构件在廉价机器上
a)      通过多副本提高可靠性
b)      提供了容错和恢复机制
 
HDFS缺点：
>1.    低延迟数据访问
a)      比如毫秒级
b)      低延迟与高吞吐量
2.    小文件存取
a)      占用NameNode大量内存
b)      寻道时间超过读取时间
3.    并发写入、文件随机修改
a)      一个文件只能有一个写者
b)      仅支持append
HDFS对大量小文件的处理办法：对小文件压缩，就是说一万个小文件在HDFS上只作为一个文件进行存储，就是进行压缩处理。

# mapreduce的优缺点
## 优点：
>1.易于编程；
2.良好的扩展性；
3.高容错性；
4.适合PB级别以上的大数据的分布式离线批处理。

## 缺点：

>1.难以实时计算（MapReduce处理的是存储在本地磁盘上的离线数据）
2.不能流式计算（MapReduce设计处理的数据源是静态的）
3.难以DAG计算（有向无环图计算，由于多个任务存在依赖关系，后一个应用
的输入是前一个应用的输出。解决这一问题的方式有Apache的Tez计算框架，
它是基于hadoop Yarn之上的DAG计算框架，它将MapReduce任务分解为多个子任务
同时可以把多个Map/ Reduce任务合并成一个大的DAG任务，这样当前一个任务完成
之后，直接将结果输出给下一个任务，不用将结果写到磁盘之上，减少了Map/Reduce
之间的文件存储。同时合理的组合其子过程，减少了任务的运行时间。

## 小结

>MapReduce适合离线处理大批量的数据，在Map阶段结束之后将数据大量的写入磁盘，然后再交给Reduce阶段去处理。这样的话数据的处理效果相对较慢，并且不利于实时计算、流式计算和DAG计算，但是这样的一个好处就是：将数据写入磁盘，出于系统的容错考虑，避免了系统出错带来的数据的的丢失。整体来说，MapReduce的处理效果还是不错的，尤其对于大数据的分布式、高容错批处理。并且系统的良好的可扩展性也是有很大的优势的。

>**说白了就是处理大数据的分析,并且高容错,中间环节出问题,会重新计算,但是处理速度慢,并且高延迟所以用作离线查询分析**

# Mapreduce和Spark的比较
>**首先,spark的功能型更强大,mapreduce的每一个job的完成都会有从hdfs读文件,然后计算然后存储,每个人物相对独立,相当于RPC中的每个人负责一个业务**
>**而spark的把这种计算规模化了,也就是读取到的数据放到内存中,其他的task可以直接读取你已经读取的数据,并且计算的中间数据也会作为一个单元储存,供其他任务使用,相当于把任务拆分了,流水线专人专事**

## mapreduce
>传统的MapReduce虽然具有自动容错、平衡负载和可拓展性的优点，但是其最大缺点是采用非循环式的数据流模型（由于每一次MapReduce的输入/输出数据，都需要读取/写入磁盘当中，如果涉及到多个作业流程，就意味着多次读取和写入HDFS），使得在迭代计算式要进行大量的磁盘IO操作。

>仅支持Map和Reduce两种操作
Map中间结果需要写磁盘
任务调度和启动开销大
无法充分利用内存
Map和Reduce都需要排序
不适合迭代计算

## spark
>Spark能够实现对MapReduce性能的直线超越，得益于Spark中一种名为RDD（Resilient Distributed DataSets）的数据处理模型。
>RDD抽象出一个被分区、不可变、且能并行操作的数据集；从HDFS读取的需要计算的数据，在经过处理后的中间结果会作为RDD单元缓存到内存当中，并可以作为下一次计算的输入信息。最终Spark只需要读取和写入一次HDFS，这样就避免了Hadoop MapReduce的大IO操作。

>丰富的API（Java、Scala、Python、R四种语言，sort、join等高效算子）
DAG执行引擎，中间结果不落盘
线程池模型减少task启动开销
充分利用内存，减少磁盘IO
避免不必要的排序操作
适合迭代计算，比如机器学习算法

![][1]

## spark的其他优势
>Spark的优势不仅体现在性能提升上的，Spark框架为批处理（Spark Core），交互式（Spark SQL），流式（Spark Streaming），机器学习（MLlib），图计算（GraphX）提供一个统一的数据处理平台，这相对于使用Hadoop有很大优势。
>交互式说白了就是快速响应,可以互相交流

# Yarn框架

>是mapreduce的载体,mapreduce的应用请求会发送到yarn上,然后yarn会为它分配资源,然后在各节点上运行.

>旧的 Hadoop 架构受到了 JobTracker 的高度约束，JobTracker 负责整个集群的资源管理和作业调度。新的 YARN 架构打破了这种模型，允许一个新 ResourceManager 管理跨应用程序的资源使用，ApplicationMaster 负责管理作业的执行。这一更改消除了一处瓶颈，还改善了将 Hadoop 集群扩展到比以前大得多的配置的能力。此外，不同于传统的 MapReduce，YARN 允许使用 Message Passing Interface 等标准通信模式，同时执行各种不同的编程模型，包括图形处理、迭代式处理、机器学习和一般集群计算。

>随着 YARN 的出现，您不再受到更简单的 MapReduce 开发模式约束，而是可以创建更复杂的分布式应用程序。实际上，您可以将 MapReduce 模型视为 YARN 架构可运行的一些应用程序中的其中一个，只是为自定义开发公开了基础框架的更多功能。这种能力非常强大，因为 YARN 的使用模型几乎没有限制，不再需要与一个集群上可能存在的其他更复杂的分布式应用程序框架相隔离，就像 MRv1 一样。甚至可以说，随着 YARN 变得更加健全，它有能力取代其他一些分布式处理框架，从而完全消除了专用于其他框架的资源开销，同时还简化了整个系统。


# hive,pig,hbase,的不同
## Pig

>一种操作hadoop的轻量级脚本语言，最初又雅虎公司推出，不过现在正在走下坡路了。当初雅虎自己慢慢退出pig的维护之后将它开源贡献到开源社区由所有爱好者来维护。不过现在还是有些公司在用，不过我认为与其使用pig不如使用hive。：）

>Pig是一种数据流语言，用来快速轻松的处理巨大的数据。

>Pig包含两个部分：Pig Interface,Pig Latin。

>Pig可以非常方便的处理HDFS和HBase的数据，和Hive一样,Pig可以非常高效的处理其需要做的，通过直接操作Pig查询可以节省大量的劳动和时间。当你想在你的数据上做一些转换，并且不想编写MapReduce jobs就可以用Pig.

## Hive

>不想用程序语言开发MapReduce的朋友比如DB们，熟悉SQL的朋友可以使用Hive开离线的进行数据处理与分析工作。

>注意Hive现在适合在离线下进行数据的操作，就是说不适合在挂在真实的生产环境中进行实时的在线查询或操作，因为一个字“慢”。相反

>起源于FaceBook,Hive在Hadoop中扮演数据仓库的角色。建立在Hadoop集群的最顶层，对存储在Hadoop群上的数据提供类SQL的接口进行操作。你可以用 HiveQL进行select,join,等等操作。

>如果你有数据仓库的需求并且你擅长写SQL并且不想写MapReduce jobs就可以用Hive代替。

## HBase

>HBase作为面向列的数据库运行在HDFS之上，HDFS缺乏随即读写操作，HBase正是为此而出现。HBase以Google BigTable为蓝本，以键值对的形式存储。项目的目标就是快速在主机内数十亿行数据中定位所需的数据并访问它。

>HBase是一个数据库，一个NoSql的数据库，像其他数据库一样提供随即读写功能，Hadoop不能满足实时需要，HBase正可以满足。如果你需要实时访问一些数据，就把它存入HBase。

>你可以用Hadoop作为静态数据仓库，HBase作为数据存储，放那些进行一些操作会改变的数据。

## Pig VS Hive

>Hive更适合于数据仓库的任务，Hive主要用于静态的结构以及需要经常分析的工作。Hive与SQL相似促使 其成为Hadoop与其他BI工具结合的理想交集。

>Pig赋予开发人员在大数据集领域更多的灵活性，并允许开发简洁的脚本用于转换数据流以便嵌入到较大的 应用程序。

>Pig相比Hive相对轻量，它主要的优势是相比于直接使用Hadoop Java APIs可大幅削减代码量。正因为如此，Pig仍然是吸引大量的软件开发人员。

>Hive和Pig都可以与HBase组合使用，Hive和Pig还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单

## Hive VS HBase

>Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。

## 总结
>想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。
Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。

# Hive与HBase的区别
## 1. 两者分别是什么？  

 >Apache Hive是一个构建在Hadoop基础设施之上的数据仓库。通过Hive可以使用HQL语言查询存放在HDFS上的数据。HQL是一种类SQL语言，这种语言最终被转化为Map/Reduce. 虽然Hive提供了SQL查询功能，但是Hive不能够进行交互查询--因为它只能够在Haoop上批量的执行Hadoop。

   >Apache HBase是一种Key/Value系统，它运行在HDFS之上。和Hive不一样，Hbase的能够在它的数据库上实时运行，而不是运行MapReduce任务。Hive被分区为表格，表格又被进一步分割为列簇。列簇必须使用schema定义，列簇将某一类型列集合起来（列不要求schema定义）。例如，“message”列簇可能包含：“to”, ”from” “date”, “subject”, 和”body”. 每一个 key/value对在Hbase中被定义为一个cell，每一个key由row-key，列簇、列和时间戳。在Hbase中，行是key/value映射的集合，这个映射通过row-key来唯一标识。Hbase利用Hadoop的基础设施，可以利用通用的设备进行水平的扩展。

## 2. 两者的特点

  >Hive帮助熟悉SQL的人运行MapReduce任务。因为它是JDBC兼容的，同时，它也能够和现存的SQL工具整合在一起。运行Hive查询会花费很长时间，因为它会默认遍历表中所有的数据。虽然有这样的缺点，一次遍历的数据量可以通过Hive的分区机制来控制。分区允许在数据集上运行过滤查询，这些数据集存储在不同的文件夹内，查询的时候只遍历指定文件夹（分区）中的数据。这种机制可以用来，例如，只处理在某一个时间范围内的文件，只要这些文件名中包括了时间格式。

   >HBase通过存储key/value来工作。它支持四种主要的操作：增加或者更新行，查看一个范围内的cell，获取指定的行，删除指定的行、列或者是列的版本。版本信息用来获取历史数据（每一行的历史数据可以被删除，然后通过Hbase compactions就可以释放出空间）。虽然HBase包括表格，但是schema仅仅被表格和列簇所要求，列不需要schema。Hbase的表格包括增加/计数功能。

## 3. 限制

  >Hive目前不支持更新操作。另外，由于hive在hadoop上运行批量操作，它需要花费很长的时间，通常是几分钟到几个小时才可以获取到查询的结果。Hive必须提供预先定义好的schema将文件和目录映射到列，并且Hive与ACID不兼容。

   >HBase查询是通过特定的语言来编写的，这种语言需要重新学习。类SQL的功能可以通过Apache Phonenix实现，但这是以必须提供schema为代价的。另外，Hbase也并不是兼容所有的ACID特性，虽然它支持某些特性。最后但不是最重要的--为了运行Hbase，Zookeeper是必须的，zookeeper是一个用来进行分布式协调的服务，这些服务包括配置服务，维护元信息和命名空间服务。

## 4. 应用场景

   >Hive适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。Hive不应该用来进行实时的查询。因为它需要很长时间才可以返回结果。

   >Hbase非常适合用来进行大数据的实时查询。Facebook用Hbase进行消息和实时的分析。它也可以用来统计Facebook的连接数。

## 5. 总结

   >Hive和Hbase是两种基于Hadoop的不同技术--Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key/vale数据库。当然，这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到Hbase，设置再从Hbase写回Hive。

# HBase的理解
##  Hbase的优缺点 
- 1 列的可以动态增加，并且列为空就不存储数据,节省存储空间.

- 2 Hbase自动切分数据，使得数据存储自动具有水平scalability.

- 3 Hbase可以提供高并发读写操作的支持

## Hbase的缺点：

- 1 不能支持条件查询，只支持按照Row key来查询.

- 2 暂时不能支持Master server的故障切换,当Master宕机后,整个存储系统就会挂掉.

## 补充
- 1.数据类型，HBase只有简单的字符类型，所有的类型都是交由用户自己处理，它只保存字符串。而关系数据库有丰富的类型和存储方式。
- 2.数据操作：HBase只有很简单的插入、查询、删除、清空等操作，表和表之间是分离的，没有复杂的表和表之间的关系，而传统数据库通常有各式各样的函数和连接操作。  
- 3.存储模式：HBase是基于列存储的，每个列族都由几个文件保存，不同的列族的文件时分离的。而传统的关系型数据库是基于表格结构和行模式保存的 
- 4.数据维护，HBase的更新操作不应该叫更新，它实际上是插入了新的数据，而传统数据库是替换修改
- 5.可伸缩性，Hbase这类分布式数据库就是为了这个目的而开发出来的，所以它能够轻松增加或减少硬件的数量，并且对错误的兼容性比较高。而传统数据库通常需要增加中间层才能实现类似的功能


##  超大数据量
>当数据量越来越大，RDBMS数据库撑不住了，就出现了读写分离策略，通过一个Master专门负责写操作，多个Slave负责读操作，服务器成本倍增。随着压力增加，Master撑不住了，这时就要分库了，把关联不大的数据分开部署，一些join查询不能用了，需要借助中间层。随着数据量的进一步增加，一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按ID取模分成多个表以减少单个表的记录数。经历过这些事的人都知道过程是多么的折腾。采用HBase就简单了，只需要加机器即可，HBase会自动水平切分扩展，跟Hadoop的无缝集成保障了其数据可靠性（HDFS）和海量数据分析的高性能（MapReduce）。

## 存储结构
>即HTable按Row key自动排序，每个Row包含任意数量个Columns，Columns之间按Column key自动排序，每个Column包含任意数量个Values。理解该存储结构将有助于查询结果的迭代。

  [1]: https://www.github.com/zyzfirst/note_images/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1509206309656.jpg