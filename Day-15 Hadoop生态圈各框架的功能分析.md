---
title: Day-15 Hadoop生态圈各框架的功能分析
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---


# HDFS的优缺点
## HDFS的优点：
        1、处理超大文件
                这里的超大文件通常是指百MB、甚至数百TB大小的文件。目前在实际应用中，HDFS已经能用来存储管理PB级的数据了。
        2、流式的访问数据
                HDFS的设计建立在“一次写入、多次读写”任务的基础上。这意味着一个数据集一旦由数据源生成，就会被复制分发到不同的存储节点中，然后响应各种各样的数据分析任务请求。在多数情况下，分析任务都会涉及数据集中的大部分数据，也就是说，对HDFS来说，请求读取整个数据集要比读取一条记录更加高效。
        3、运行于廉价的商用机器集群上
                Hadoop设计对应急需求比较低，只须运行在低廉的商用硬件集群上，而无需在昂贵的高可用性机器上。廉价的商用机也就意味着大型集群中出现节点故障情况的概率非常高。HDFS遇到了上述故障时，被设计成能够继续运行且不让用户察觉到明显的中断。
## HDFS的缺点：
        1、不适合低延迟数据访问
                如果要处理一些用户要求时间比较短的低延迟应用请求，则HDFS不适合。HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。
                改进策略：
                        对于那些有低延时要求的应用程序，HBase是一个更好的选择，通过上层数据管理项目尽可能地弥补这个不足。在性能上有了很大的提升，它的口号是goes real time。使用缓存或多个master设计可以降低Clinet的数据请求压力，以减少延时。
        2、无法高效存储大量的小文件
                因为NameNode把文件系统的元数据放置在内存中，所有文件系统所能容纳的文件数目是由NameNode的内存大小来决定。还有一个问题就是，因为MapTask的数量是由Splits来决定的，所以用MR处理大量的小文件时，就会产生过多的MapTask，线程管理开销将会增加作业时间。当Hadoop处理很多小文件(文件大小小于HDFS中Block大小)的时候，由于FileInputFormat不会对小文件进行划分，所以每一个小文件都会被当做一个Split并分配一个Map任务，导致效率底下。
                例如：一个1G的文件，会被划分成16个64MB的Split，并分配16个Map任务处理，而10000个100Kb的文件会被10000个Map任务处理。
                改进策略：
                        要想让HDFS能处理好小文件，有不少方法。利用SequenceFile、MapFile、Har等方式归档小文件，这个方法的原理就是把小文件归档起来管理，HBase就是基于此的。
        3、不支持多用户写入及任意修改文件
                在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作，目前HDFS还不支持多个用户对同一文件的写操作，以及在文件任意位置进行修改。

## 综合
HDFS优点：
>1.    高容错性。
a)      数据自动保存多个副本
b)      副本丢失后，自动恢复
2.    适合批处理
a)      移动计算而非移动数据
b)      数据位置暴露给计算框架
3.    适合大数据处理
a)      GB、TB、甚至PB级数据
b)      百万规模以上的文件数量
c)       10K + 节点
4.    可构件在廉价机器上
a)      通过多副本提高可靠性
b)      提供了容错和恢复机制
 
HDFS缺点：
>1.    低延迟数据访问
a)      比如毫秒级
b)      低延迟与高吞吐量
2.    小文件存取
a)      占用NameNode大量内存
b)      寻道时间超过读取时间
3.    并发写入、文件随机修改
a)      一个文件只能有一个写者
b)      仅支持append
HDFS对大量小文件的处理办法：对小文件压缩，就是说一万个小文件在HDFS上只作为一个文件进行存储，就是进行压缩处理。

# mapreduce的优缺点
## 优点：
>1.易于编程；
2.良好的扩展性；
3.高容错性；
4.适合PB级别以上的大数据的分布式离线批处理。

## 缺点：

>1.难以实时计算（MapReduce处理的是存储在本地磁盘上的离线数据）
2.不能流式计算（MapReduce设计处理的数据源是静态的）
3.难以DAG计算（有向无环图计算，由于多个任务存在依赖关系，后一个应用
的输入是前一个应用的输出。解决这一问题的方式有Apache的Tez计算框架，
它是基于hadoop Yarn之上的DAG计算框架，它将MapReduce任务分解为多个子任务
同时可以把多个Map/ Reduce任务合并成一个大的DAG任务，这样当前一个任务完成
之后，直接将结果输出给下一个任务，不用将结果写到磁盘之上，减少了Map/Reduce
之间的文件存储。同时合理的组合其子过程，减少了任务的运行时间。

## 小结

>MapReduce适合离线处理大批量的数据，在Map阶段结束之后将数据大量的写入磁盘，然后再交给Reduce阶段去处理。这样的话数据的处理效果相对较慢，并且不利于实时计算、流式计算和DAG计算，但是这样的一个好处就是：将数据写入磁盘，出于系统的容错考虑，避免了系统出错带来的数据的的丢失。整体来说，MapReduce的处理效果还是不错的，尤其对于大数据的分布式、高容错批处理。并且系统的良好的可扩展性也是有很大的优势的。

>**说白了就是处理大数据的分析,并且高容错,中间环节出问题,会重新计算,但是处理速度慢,并且高延迟所以用作离线查询分析**

# Mapreduce和Spark的比较
>**首先,spark的功能型更强大,mapreduce的每一个job的完成都会有从hdfs读文件,然后计算然后存储,每个人物相对独立,相当于RPC中的每个人负责一个业务**
>**而spark的把这种计算规模化了,也就是读取到的数据放到内存中,其他的task可以直接读取你已经读取的数据,并且计算的中间数据也会作为一个单元储存,供其他任务使用,相当于把任务拆分了,流水线专人专事**

## mapreduce
>传统的MapReduce虽然具有自动容错、平衡负载和可拓展性的优点，但是其最大缺点是采用非循环式的数据流模型（由于每一次MapReduce的输入/输出数据，都需要读取/写入磁盘当中，如果涉及到多个作业流程，就意味着多次读取和写入HDFS），使得在迭代计算式要进行大量的磁盘IO操作。

>仅支持Map和Reduce两种操作
Map中间结果需要写磁盘
任务调度和启动开销大
无法充分利用内存
Map和Reduce都需要排序
不适合迭代计算

## spark
>Spark能够实现对MapReduce性能的直线超越，得益于Spark中一种名为RDD（Resilient Distributed DataSets）的数据处理模型。
>RDD抽象出一个被分区、不可变、且能并行操作的数据集；从HDFS读取的需要计算的数据，在经过处理后的中间结果会作为RDD单元缓存到内存当中，并可以作为下一次计算的输入信息。最终Spark只需要读取和写入一次HDFS，这样就避免了Hadoop MapReduce的大IO操作。

>丰富的API（Java、Scala、Python、R四种语言，sort、join等高效算子）
DAG执行引擎，中间结果不落盘
线程池模型减少task启动开销
充分利用内存，减少磁盘IO
避免不必要的排序操作
适合迭代计算，比如机器学习算法

![][1]

## spark的其他优势
>Spark的优势不仅体现在性能提升上的，Spark框架为批处理（Spark Core），交互式（Spark SQL），流式（Spark Streaming），机器学习（MLlib），图计算（GraphX）提供一个统一的数据处理平台，这相对于使用Hadoop有很大优势。
>交互式说白了就是快速响应,可以互相交流


# hive,pig,hbase,的不同
## Pig

>一种操作hadoop的轻量级脚本语言，最初又雅虎公司推出，不过现在正在走下坡路了。当初雅虎自己慢慢退出pig的维护之后将它开源贡献到开源社区由所有爱好者来维护。不过现在还是有些公司在用，不过我认为与其使用pig不如使用hive。：）

>Pig是一种数据流语言，用来快速轻松的处理巨大的数据。

>Pig包含两个部分：Pig Interface,Pig Latin。

>Pig可以非常方便的处理HDFS和HBase的数据，和Hive一样,Pig可以非常高效的处理其需要做的，通过直接操作Pig查询可以节省大量的劳动和时间。当你想在你的数据上做一些转换，并且不想编写MapReduce jobs就可以用Pig.

## Hive

>不想用程序语言开发MapReduce的朋友比如DB们，熟悉SQL的朋友可以使用Hive开离线的进行数据处理与分析工作。

>注意Hive现在适合在离线下进行数据的操作，就是说不适合在挂在真实的生产环境中进行实时的在线查询或操作，因为一个字“慢”。相反

>起源于FaceBook,Hive在Hadoop中扮演数据仓库的角色。建立在Hadoop集群的最顶层，对存储在Hadoop群上的数据提供类SQL的接口进行操作。你可以用 HiveQL进行select,join,等等操作。

>如果你有数据仓库的需求并且你擅长写SQL并且不想写MapReduce jobs就可以用Hive代替。

## HBase

>HBase作为面向列的数据库运行在HDFS之上，HDFS缺乏随即读写操作，HBase正是为此而出现。HBase以Google BigTable为蓝本，以键值对的形式存储。项目的目标就是快速在主机内数十亿行数据中定位所需的数据并访问它。

>HBase是一个数据库，一个NoSql的数据库，像其他数据库一样提供随即读写功能，Hadoop不能满足实时需要，HBase正可以满足。如果你需要实时访问一些数据，就把它存入HBase。

>你可以用Hadoop作为静态数据仓库，HBase作为数据存储，放那些进行一些操作会改变的数据。

## Pig VS Hive

>Hive更适合于数据仓库的任务，Hive主要用于静态的结构以及需要经常分析的工作。Hive与SQL相似促使 其成为Hadoop与其他BI工具结合的理想交集。

>Pig赋予开发人员在大数据集领域更多的灵活性，并允许开发简洁的脚本用于转换数据流以便嵌入到较大的 应用程序。

>Pig相比Hive相对轻量，它主要的优势是相比于直接使用Hadoop Java APIs可大幅削减代码量。正因为如此，Pig仍然是吸引大量的软件开发人员。

>Hive和Pig都可以与HBase组合使用，Hive和Pig还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单

## Hive VS HBase

>Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。

## 总结
>想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。
Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。

  [1]: https://www.github.com/zyzfirst/note_images/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1509206309656.jpg